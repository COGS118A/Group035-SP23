{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Cristian Antonio-Hernandez\n",
    "- Rahul Puranam\n",
    "- Ricardo Sedano\n",
    "- Jason Shao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Recieving email spam has become an issue in  users' digital wellbeing; email spam has the potential to overflow inboxes, invite malware to devices, and scam users for personal information. Our goal is to develop an effective email spam detection system. We will be using a dataset consisting of labeled emails, where each email is classified as either spam or non-spam. The data represents various features extracted from the emails, such as the presence of certain keywords, email header information, and textual content. We will employ machine learning algorithms to train a model on this labeled data to accurately classify incoming emails as spam or non-spam. The performance of the system will be measured by evaluating its ability to correctly classify a new set of emails, using metrics such as accuracy, precision, recall, and F1-score. Our objective is to achieve high accuracy and minimize false positives (legitimate emails classified as spam) and false negatives (spam emails classified as legitimate), ensuring an efficient and reliable spam detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "The field of email spam detection has been extensively researched, with significant prior work paving the way for advancements in this area. Various techniques and approaches have been explored to tackle the problem of email classification, aiming to accurately distinguish between spam and non-spam emails.\n",
    "\n",
    "Researchers have employed machine learning algorithms, such as support vector machines (SVMs), naive Bayes classifiers, and ensemble methods, to build effective spam detection models<a name=\"solanki\"></a>[<sup>[1]</sup>](#solanki)<a name=\"dada\"></a>[<sup>[2]</sup>](#dada). These models utilize features extracted from email content, such as keyword presence, textual analysis, and email header information, to make predictions on the classification of incoming emails.\n",
    "\n",
    "Feature engineering has been a crucial aspect of this research, as it involves selecting and extracting relevant features that contribute to the identification of spam emails<a name=\"dada\"></a>[<sup>[2]</sup>](#dada). Additionally, researchers have explored the use of natural language processing techniques to analyze the text of emails, including techniques like text tokenization, stemming, and TF-IDF weighting<a name=\"sahami\"></a>[<sup>[3]</sup>](#sahami)<a name=\"yang\"></a>[<sup>[4]</sup>](#yang)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Our goal is to develop an effective email spam classification system by leveraging features such as keyword presence, textual analysis, and email header information. This research aims to address the following questions:\n",
    "\n",
    "- How can we accurately predict whether an email is spam or not spam based on its content, utilizing features such as keyword presence, textual analysis, and email header information?\n",
    "\n",
    "- Which machine learning algorithms, such as Support Vector Machines, Decision Trees, Naive Bayes classifiers, or ensemble methods like Random Forest, are most suitable for solving this email spam classification problem?\n",
    "\n",
    "We will collect a dataset consisting of a representative sample of emails, including both spam and non-spam examples. The dataset will be preprocessed to extract relevant features and labeled accordingly. We will then train and evaluate different machine learning models using appropriate performance metrics, such as accuracy.\n",
    "\n",
    "By conducting this research, we aim to develop a robust and reliable email spam classification system that can effectively differentiate between spam and non-spam emails, while minimizing false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset selected for the project is the UCI Machine Learning Repository's 'Spambase Data Set'<a name=\"uci\"></a>[<sup>[5]</sup>](#uci), which is comprised of 4601 observations and 57 continuous variables along with 1 nominal variable. In our data, an observation consists of percentage of word frequncy for 48 words, percentage of character frequncy for 6 special charcters, average length of uninterrupted sequences of capital letters, length of longest uninterrupted sequence of capital letters, total number of capital letters in the e-mail, and a nominal denoter of whether an email is spam or not. For the last variable, it must be noted that 0 represents a email that is not spam, and 1 represents a spam email. \n",
    "\n",
    "Because our project deals with a categorical classificiation problem, the critical variables could be represented in a regression model. Pertaining to the scenario, critical values would hypothetically be tied to special character, word, and capital letter usage.\n",
    "\n",
    "Additional to obtaining the data, our team did not handle data more than needed in order to preserve integrity in the data, and reduce bias thoughout; the dataset had very little cleaning, and needed adjusting. The dataset and names file came separate, so in order to prepare our dataset, we used the df.columns() function to name the columns according to their respective variable.\n",
    "\n",
    "In order to illustrate an effective classification model and to help midigate overfitting, L2 regularization, pruning, and cross-validation can be valuable processes needed to sighly transform data, and balance the bias-variance tradeoff.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>address</th>\n",
       "      <th>all</th>\n",
       "      <th>3d</th>\n",
       "      <th>our</th>\n",
       "      <th>over</th>\n",
       "      <th>remove</th>\n",
       "      <th>internet</th>\n",
       "      <th>order</th>\n",
       "      <th>mail</th>\n",
       "      <th>...</th>\n",
       "      <th>;</th>\n",
       "      <th>(</th>\n",
       "      <th>[</th>\n",
       "      <th>!</th>\n",
       "      <th>$</th>\n",
       "      <th>#</th>\n",
       "      <th>Capital Run Length Average</th>\n",
       "      <th>Capital Run Length Longest</th>\n",
       "      <th>Capital Run Length Total</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      make  address   all   3d   our  over  remove  internet  order  mail  \\\n",
       "0     0.00     0.64  0.64  0.0  0.32  0.00    0.00      0.00   0.00  0.00   \n",
       "1     0.21     0.28  0.50  0.0  0.14  0.28    0.21      0.07   0.00  0.94   \n",
       "2     0.06     0.00  0.71  0.0  1.23  0.19    0.19      0.12   0.64  0.25   \n",
       "3     0.00     0.00  0.00  0.0  0.63  0.00    0.31      0.63   0.31  0.63   \n",
       "4     0.00     0.00  0.00  0.0  0.63  0.00    0.31      0.63   0.31  0.63   \n",
       "...    ...      ...   ...  ...   ...   ...     ...       ...    ...   ...   \n",
       "4596  0.31     0.00  0.62  0.0  0.00  0.31    0.00      0.00   0.00  0.00   \n",
       "4597  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00   \n",
       "4598  0.30     0.00  0.30  0.0  0.00  0.00    0.00      0.00   0.00  0.00   \n",
       "4599  0.96     0.00  0.00  0.0  0.32  0.00    0.00      0.00   0.00  0.00   \n",
       "4600  0.00     0.00  0.65  0.0  0.00  0.00    0.00      0.00   0.00  0.00   \n",
       "\n",
       "      ...      ;      (    [      !      $      #  Capital Run Length Average  \\\n",
       "0     ...  0.000  0.000  0.0  0.778  0.000  0.000                       3.756   \n",
       "1     ...  0.000  0.132  0.0  0.372  0.180  0.048                       5.114   \n",
       "2     ...  0.010  0.143  0.0  0.276  0.184  0.010                       9.821   \n",
       "3     ...  0.000  0.137  0.0  0.137  0.000  0.000                       3.537   \n",
       "4     ...  0.000  0.135  0.0  0.135  0.000  0.000                       3.537   \n",
       "...   ...    ...    ...  ...    ...    ...    ...                         ...   \n",
       "4596  ...  0.000  0.232  0.0  0.000  0.000  0.000                       1.142   \n",
       "4597  ...  0.000  0.000  0.0  0.353  0.000  0.000                       1.555   \n",
       "4598  ...  0.102  0.718  0.0  0.000  0.000  0.000                       1.404   \n",
       "4599  ...  0.000  0.057  0.0  0.000  0.000  0.000                       1.147   \n",
       "4600  ...  0.000  0.000  0.0  0.125  0.000  0.000                       1.250   \n",
       "\n",
       "      Capital Run Length Longest  Capital Run Length Total  Spam  \n",
       "0                             61                       278     1  \n",
       "1                            101                      1028     1  \n",
       "2                            485                      2259     1  \n",
       "3                             40                       191     1  \n",
       "4                             40                       191     1  \n",
       "...                          ...                       ...   ...  \n",
       "4596                           3                        88     0  \n",
       "4597                           4                        14     0  \n",
       "4598                           6                       118     0  \n",
       "4599                           5                        78     0  \n",
       "4600                           5                        40     0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\", header = None)\n",
    "df.columns = ['make','address','all','3d','our','over','remove','internet','order','mail','recieve','will','people','report','addresses','free','business','email','you','credit','your','font','000','money','hp','hpl','george','650','lab','labs','telnet','857','data','415','85','technology','1999','parts','pm','direct','cs','meeting','original','project','re','edu','table','conference',';','(','[','!','$','#','Capital Run Length Average','Capital Run Length Longest','Capital Run Length Total','Spam']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "To address the email spam classification problem, we decided to utilize Support Vector Machines (SVM). SVMs are effective in separating data points into different classes by finding an optimal hyperplane that maximizes the margin between the classes. In our case, we aim to create a decision boundary that accurately distinguishes between spam and non-spam emails. By constructing a margin around this decision boundary, we can achieve better generalization and potentially reduce both false positives and false negatives. We will be implementing gradient descent to find the minimum loss and possibly using kernels to transform our data into data that is linearly separable in higher dimensions. Kernels with SVMs can help us find a linearly separable representation of the data, even if the original features were not linearly separable. By applying appropriate kernels, we can potentially improve the separation between spam and non-spam emails, enhancing the accuracy of our classification model.\n",
    "To evaluate the performance of our solution, we will split our dataset into training and testing sets. During training, we will fit the SVM model on the labeled training data and optimize the hyperparameters using techniques like cross-validation. Then, we will use the testing dataset to measure the accuracy of our classifier. Accuracy provides an overall indication of how well the model performs in terms of correct predictions. We will utilize the F1 score, which considers both precision and recall, to assess the model's performance specifically in terms of false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "One evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model is the F1-score (F1-score = $\\frac{2 * (\\text{Precision} * \\text{Recall})}{(\\text{Precision} + \\text{Recall})}$), assessing both precision and recall, as precision represents the ability of the model to correctly identify spam emails among the emails it classifies as spam, and recall measures the ability of the model to identify all the actual spam emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "To understand some of the data, we can take a look at the average captial run length. In the below graph, we can see there is a clear difference between the spam email and the normal busniess emails, suggesting there may be a clear linear divide between the two categories of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spam_df = df[df['Spam'] == 1]\n",
    "non_spam_df = df[df['Spam'] == 0]\n",
    "spam_avg_cap_run_length = spam_df['Capital Run Length Average'].mean()\n",
    "non_spam_avg_cap_run_length = non_spam_df['Capital Run Length Average'].mean()\n",
    "plt.bar(['Spam', 'Not Spam'], [spam_avg_cap_run_length, non_spam_avg_cap_run_length])\n",
    "plt.xlabel('Email Type')\n",
    "plt.ylabel('Average Capital Run Length')\n",
    "plt.title('Distribution of Average Capital Run Length: Spam vs Not Spam')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore this possibility first beginning with SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Spam'])\n",
    "y = df['Spam']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling spam detection through SVM (Linear, Poly, RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a SVM with linear kernel\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svm = SVC(kernel='linear', C=C)\n",
    "%time svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "yhat = svm.predict(X_test)\n",
    "print(classification_report(y_test, yhat))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, yhat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=C)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "yhat = svm_poly.predict(X_test)\n",
    "print(classification_report(y_test, yhat))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, yhat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a SVM with RBF kernel\n",
    "svm_rbf = SVC(kernel='rbf', gamma=0.7, C=C)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "yhat = svm_rbf.predict(X_test)\n",
    "print(classification_report(y_test, yhat))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, yhat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the 3 SVMs, we see that in the linear model performed the best, with both Polynomial and RBF in fact performing worse than random chance when it came to identified which was indeed spam. This supports the idea that there is a clear line between the two categories which could be used to accuratly predict any emails. Let's test this idea through other models, such as Decision Trees and Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling spam detection through Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "%time dt.fit(X_train,y_train)\n",
    "# Accuracy of the model\n",
    "dt.score(X_test,y_test)\n",
    "# Checking to see if model is overfitting\n",
    "dt.score(X_train, y_train)\n",
    "\n",
    "\n",
    "yhat = dt.predict(X_test)\n",
    "print(classification_report(y_test, yhat))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, yhat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears as though Decision Trees perform just about the same as the linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest - Ensemble Decision Trees\n",
    "rf = RandomForestClassifier(n_estimators = 15)\n",
    "%time rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "rf.score(X_train, y_train)\n",
    "\n",
    "\n",
    "yhat = rf.predict(X_test)\n",
    "print(classification_report(y_test, yhat))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, yhat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it appears as though the Random Forest model performs much better at the classification task than the linear SVM or the Decision Tree. Let's try using bagging and AdaBoost to improve the f1-score of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging \n",
    "bg = BaggingClassifier(DecisionTreeClassifier(), max_samples = 0.5, max_features = 1.0, n_estimators = 20)\n",
    "%time bg.fit(X_train, y_train)\n",
    "bg.score(X_test, y_test)\n",
    "bg.score(X_train, y_train)\n",
    "\n",
    "\n",
    "yhat = bg.predict(X_test)\n",
    "print(classification_report(y_test, yhat))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, yhat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting - Ada Boost\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = 5, learning_rate = 1)\n",
    "%time adb.fit(X_train, y_train)\n",
    "adb.score(X_test, y_test)\n",
    "adb.score(X_train, y_train)\n",
    "\n",
    "\n",
    "yhat = adb.predict(X_test)\n",
    "print(classification_report(y_test, yhat))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, yhat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that ultimately, the Random Forest model performs the best even with other changes made to the Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "The most obvious ethical concern that should be addressed is having access to emails, of which for the average email recipient, may include personal information, like residential address, close contacts, and calendar events. Going back a step, people may not even want their email address to get leaked, so having this data be used may raise concern. Continuing on the email message contents, a detection service would have to scan a large portion of the email, or each line of text to properly make a decision. Having an algorithm read every email automatically aould also cause concern.\n",
    "\n",
    "To address these issues, a step toward the correct solution would be to automatically not store and get rid of all text that the model takes in. From a user standpoint, it may also be helpful to give permission to the model to only filter email spam from senders outside of the recipients most popular contacts, or turn off or deactivative the spam detection completely if the user feels unsure if the detection service is too invasive or unethical.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Email spam continues to pose a threat to email service users throughout many instances. By using an email dataset, we aim is to develop an effective email spam detection system, and nby identifying the most accruate model, the random forest - ensemble decision tree model. With this model, we produce an accuracy score above 95 percent, meaning 95 percent of spam is expected to be detected, and given the problem, the spam would get deleted. The next steps would be to implement the spam detection into a preliminary version of a spam-free email service. However, a more practical choice would be to impove the understanding of what variables or factors not accounted for in this project may influence a more accurate spam detection service. This understanding can be impoved in recording more email data, and hypothesize upon new factors influencing spam deteection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"solanki\"></a>1.[^](#solanki): Solanki, Rohit Kumar, et al. Spam Filtering Using Hybrid Local-Global Naive Bayes Classifier, 28 Sept. 2015, www.semanticscholar.org/paper/Spam-filtering-using-hybrid-local-global-Naive-Solanki-Verma/978a7972210e2d771dac6f92e17594100ea1a8a6. <br> \n",
    "<a name=\"dada\"></a>2.[^](#dada): Dada, Emmanuel Gbenga, et al. “Machine Learning for Email Spam Filtering: Review, Approaches and Open Research Problems.” Heliyon, vol. 5, no. 6, June 2019, p. e01802, https://doi.org/10.1016/j.heliyon.2019.e01802. <br>\n",
    "<a name=\"sahami\"></a>3.[^](#sahami): Sahami, Mehran, et al. A B a Yesian Approach to Filtering Junk E-Mail. http://erichorvitz.com/ftp/junkfilter.pdf. <br>\n",
    "<a name=\"yang\"></a>4.[^](#yang): Yang, Yiming, and Xin Liu. “A Re-Examination of Text Categorization Methods.” Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval - SIGIR ’99, 1999, https://doi.org/10.1145/312624.312647. <br>\n",
    "<a name=\"uci\"></a>5.[^](#uci): “Spambase Data Set” UCI Machine Learning Repository Archives, https://archive.ics.uci.edu/ml/datasets/spambase. <br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
